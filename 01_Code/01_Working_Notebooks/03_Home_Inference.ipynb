{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bwool/RESEARCH/TRB-Home-Data-Quality-2025'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple HDA--Centroid Method (A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_home_detection(data: pd.DataFrame):\n",
    "    homes = []\n",
    "    skipped_no_night = 0\n",
    "\n",
    "    for caid, user_df in tqdm(data.groupby(\"caid\"), desc=\"Running centroid HDA\"):\n",
    "        dt = user_df['datetime_pdt'].dt\n",
    "        is_night = (dt.hour >= 19) | (dt.hour < 7)\n",
    "        night_df = user_df[is_night]\n",
    "\n",
    "        if night_df.empty:\n",
    "            skipped_no_night += 1\n",
    "            continue\n",
    "\n",
    "        home_lat = night_df['latitude'].mean()\n",
    "        home_lon = night_df['longitude'].mean()\n",
    "\n",
    "        homes.append({\n",
    "            'caid': caid,\n",
    "            'latitude': home_lat,\n",
    "            'longitude': home_lon\n",
    "        })\n",
    "\n",
    "    print(f\"Skipped {skipped_no_night} users with no nighttime observations.\")\n",
    "    return pd.DataFrame(homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15444/15444 [00:07<00:00, 1990.08it/s]\n",
      "Processing files for HDA:  11%|█         | 1/9 [00:09<01:15,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 360 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15259/15259 [00:07<00:00, 1969.95it/s]\n",
      "Processing files for HDA:  22%|██▏       | 2/9 [00:18<01:06,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 385 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15053/15053 [00:07<00:00, 1893.81it/s]\n",
      "Processing files for HDA:  33%|███▎      | 3/9 [00:28<00:57,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 351 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15369/15369 [00:08<00:00, 1897.64it/s]\n",
      "Processing files for HDA:  44%|████▍     | 4/9 [00:38<00:48,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 376 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15352/15352 [00:08<00:00, 1918.43it/s]\n",
      "Processing files for HDA:  56%|█████▌    | 5/9 [00:47<00:38,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 372 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15220/15220 [00:08<00:00, 1889.03it/s]\n",
      "Processing files for HDA:  67%|██████▋   | 6/9 [00:57<00:29,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 386 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15311/15311 [00:08<00:00, 1862.64it/s]\n",
      "Processing files for HDA:  78%|███████▊  | 7/9 [01:07<00:19,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 312 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15293/15293 [00:08<00:00, 1901.40it/s]\n",
      "Processing files for HDA:  89%|████████▉ | 8/9 [01:17<00:09,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 384 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running centroid HDA: 100%|██████████| 15185/15185 [00:07<00:00, 1936.12it/s]\n",
      "Processing files for HDA: 100%|██████████| 9/9 [01:27<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 342 users with no nighttime observations.\n",
      "Saved 134,218 home locations to: 00_Data/04_HDA_Sample_Data/2019_all_users_centroid_home_locations.csv\n"
     ]
    }
   ],
   "source": [
    "def run_centroid_hda_on_all_2019_data():\n",
    "    # === Set input/output folders ===\n",
    "    folder_2019_cleaned = \"00_Data/02_Cleaned_Sample_Data/2019_Cleaned_Data\"\n",
    "    output_file = \"00_Data/04_HDA_Sample_Data/2019_all_users_centroid_home_locations.csv\"\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # === List all parquet files ===\n",
    "    cleaned_files = [\n",
    "        os.path.join(folder_2019_cleaned, f)\n",
    "        for f in os.listdir(folder_2019_cleaned)\n",
    "        if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # === Collect all home detections ===\n",
    "    all_homes = []\n",
    "\n",
    "    for filepath in tqdm(cleaned_files, desc=\"Processing files for HDA\"):\n",
    "        try:\n",
    "            df = pd.read_parquet(filepath, engine=\"pyarrow\")\n",
    "            homes_df = centroid_home_detection(df)\n",
    "            all_homes.append(homes_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "    # === Concatenate all results and save ===\n",
    "    final_df = pd.concat(all_homes, ignore_index=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(final_df):,} home locations to: {output_file}\")\n",
    "\n",
    "run_centroid_hda_on_all_2019_data()\n",
    "# 1m 27.4 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium HDA--Grid Frequency Method (A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_to_cell_id(lat, lon, cell_size_meters=20):\n",
    "    # Approximate degree-per-meter conversion at given latitude\n",
    "    lat_deg_per_m = 1 / 111320\n",
    "    lon_deg_per_m = 1 / (40075000 * np.cos(np.radians(lat)) / 360)\n",
    "\n",
    "    lat_bin = np.floor(lat / (lat_deg_per_m * cell_size_meters))\n",
    "    lon_bin = np.floor(lon / (lon_deg_per_m * cell_size_meters))\n",
    "    return lat_bin.astype(int), lon_bin.astype(int)\n",
    "\n",
    "def grid_frequency_home_detection(data: pd.DataFrame, cell_size_meters=20):\n",
    "    homes = []\n",
    "    skipped_no_night = 0\n",
    "\n",
    "    for caid, user_df in tqdm(data.groupby(\"caid\"), desc=\"Running grid-frequency HDA\"):\n",
    "        dt = user_df['datetime_pdt'].dt\n",
    "        is_night = (dt.hour >= 19) | (dt.hour < 7)\n",
    "        night_df = user_df[is_night]\n",
    "\n",
    "        if night_df.empty:\n",
    "            skipped_no_night += 1\n",
    "            continue  # Skip users with no nighttime pings\n",
    "\n",
    "        lat = night_df['latitude'].values\n",
    "        lon = night_df['longitude'].values\n",
    "        lat_bin, lon_bin = latlon_to_cell_id(lat, lon, cell_size_meters)\n",
    "\n",
    "        # Combine bins\n",
    "        bins = list(zip(lat_bin, lon_bin))\n",
    "        bin_counts = pd.Series(bins).value_counts()\n",
    "\n",
    "        # Most frequent bin\n",
    "        top_bin = bin_counts.idxmax()\n",
    "        mask = [(a == top_bin[0]) & (b == top_bin[1]) for a, b in zip(lat_bin, lon_bin)]\n",
    "        home_points = night_df.loc[mask, ['latitude', 'longitude']]\n",
    "\n",
    "        # Mean of lat/lon within the most frequent bin\n",
    "        home_lat, home_lon = home_points.mean()\n",
    "\n",
    "        homes.append({\n",
    "            'caid': caid,\n",
    "            'latitude': home_lat,\n",
    "            'longitude': home_lon,\n",
    "            'cell_id': f\"{top_bin[0]}_{top_bin[1]}\"\n",
    "        })\n",
    "        \n",
    "    print(f\"Skipped {skipped_no_night} users with no nighttime observations.\")\n",
    "    return pd.DataFrame(homes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15444/15444 [00:15<00:00, 975.41it/s] \n",
      "Processing files for Grid-Freq HDA:  11%|█         | 1/9 [00:17<02:19, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 360 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15259/15259 [00:15<00:00, 976.44it/s] \n",
      "Processing files for Grid-Freq HDA:  22%|██▏       | 2/9 [00:34<02:00, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 385 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15053/15053 [00:15<00:00, 966.75it/s]\n",
      "Processing files for Grid-Freq HDA:  33%|███▎      | 3/9 [00:51<01:43, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 351 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15369/15369 [00:15<00:00, 998.23it/s] \n",
      "Processing files for Grid-Freq HDA:  44%|████▍     | 4/9 [01:08<01:25, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 376 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15352/15352 [00:15<00:00, 1020.51it/s]\n",
      "Processing files for Grid-Freq HDA:  56%|█████▌    | 5/9 [01:25<01:07, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 372 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15220/15220 [00:16<00:00, 942.01it/s] \n",
      "Processing files for Grid-Freq HDA:  67%|██████▋   | 6/9 [01:43<00:51, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 386 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15311/15311 [00:16<00:00, 908.79it/s] \n",
      "Processing files for Grid-Freq HDA:  78%|███████▊  | 7/9 [02:01<00:35, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 312 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15293/15293 [00:15<00:00, 971.07it/s] \n",
      "Processing files for Grid-Freq HDA:  89%|████████▉ | 8/9 [02:19<00:17, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 384 users with no nighttime observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running grid-frequency HDA: 100%|██████████| 15185/15185 [00:15<00:00, 961.69it/s]\n",
      "Processing files for Grid-Freq HDA: 100%|██████████| 9/9 [02:36<00:00, 17.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 342 users with no nighttime observations.\n",
      "Saved 134,218 home locations to: 00_Data/04_HDA_Sample_Data/2019_all_users_gridfreq_home_locations_20m.csv\n"
     ]
    }
   ],
   "source": [
    "def run_grid_frequency_hda_on_all_2019_data(cell_size_meters=20):\n",
    "    # === Set input/output paths ===\n",
    "    folder_2019_cleaned = \"00_Data/02_Cleaned_Sample_Data/2019_Cleaned_Data\"\n",
    "    output_file = f\"00_Data/04_HDA_Sample_Data/2019_all_users_gridfreq_home_locations_{cell_size_meters}m.csv\"\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # === List all parquet files ===\n",
    "    cleaned_files = [\n",
    "        os.path.join(folder_2019_cleaned, f)\n",
    "        for f in os.listdir(folder_2019_cleaned)\n",
    "        if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # === Collect all home detections ===\n",
    "    all_homes = []\n",
    "\n",
    "    for filepath in tqdm(cleaned_files, desc=\"Processing files for Grid-Freq HDA\"):\n",
    "        try:\n",
    "            df = pd.read_parquet(filepath, engine=\"pyarrow\")\n",
    "            homes_df = grid_frequency_home_detection(df, cell_size_meters=cell_size_meters)\n",
    "            all_homes.append(homes_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "    # === Concatenate all results and save ===\n",
    "    final_df = pd.concat(all_homes, ignore_index=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(final_df):,} home locations to: {output_file}\")\n",
    "\n",
    "run_grid_frequency_hda_on_all_2019_data()\n",
    "# 2m 36.7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex HDA--Binned Clustering Method (A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binned_hda_for_single_file(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    class MeanShift:\n",
    "        def __init__(self, bandwidth, bin_seeding=True, min_bin_freq=2, max_iter=50):\n",
    "            self.bandwidth = bandwidth\n",
    "            self.bin_seeding = bin_seeding\n",
    "            self.min_bin_freq = min_bin_freq\n",
    "            self.max_iter = max_iter\n",
    "            self.cluster_center = None\n",
    "            self.used_mean = False\n",
    "\n",
    "        @staticmethod\n",
    "        def get_bin_seeds(X, bin_size, min_bin_freq=1):\n",
    "            bin_sizes = defaultdict(int)\n",
    "            for point in X:\n",
    "                binned = np.round(point / bin_size)\n",
    "                bin_sizes[tuple(binned)] += 1\n",
    "            seeds = [np.array(point) * bin_size for point, freq in bin_sizes.items() if freq >= min_bin_freq]\n",
    "            return np.array(seeds) if seeds else X\n",
    "\n",
    "        @staticmethod\n",
    "        def fit_single_seed(seed, X, nbrs, bandwidth, max_iter):\n",
    "            stop_thresh = 1e-3 * bandwidth\n",
    "            mean = seed\n",
    "            for _ in range(max_iter):\n",
    "                indices = nbrs.radius_neighbors([mean], bandwidth, return_distance=False)[0]\n",
    "                if len(indices) == 0:\n",
    "                    break\n",
    "                old_mean = mean\n",
    "                mean = X[indices].mean(axis=0)\n",
    "                if np.linalg.norm(mean - old_mean) < stop_thresh:\n",
    "                    break\n",
    "            return tuple(mean), len(indices)\n",
    "\n",
    "        def fit(self, X):\n",
    "            if self.bin_seeding:\n",
    "                seeds = self.get_bin_seeds(X, self.bandwidth, self.min_bin_freq)\n",
    "            else:\n",
    "                seeds = X\n",
    "\n",
    "            nbrs = NearestNeighbors(radius=self.bandwidth).fit(X)\n",
    "            results = [self.fit_single_seed(seed, X, nbrs, self.bandwidth, self.max_iter) for seed in seeds]\n",
    "\n",
    "            clusters = {center: size for center, size in results if size > 0}\n",
    "\n",
    "            if not clusters:\n",
    "                self.cluster_center = tuple(X.mean(axis=0))\n",
    "                self.used_mean = True\n",
    "                return self\n",
    "\n",
    "            self.cluster_center = max(clusters.items(), key=lambda x: x[1])[0]\n",
    "            return self\n",
    "\n",
    "    slot_size = 30 * 60  # 30 min slots\n",
    "    radius_m = 250  # meters\n",
    "    bandwidth_deg = radius_m / 111320  # approx deg\n",
    "    night_start = 19\n",
    "    night_end = 7\n",
    "\n",
    "    homes = []\n",
    "    valid_caid = set(data['caid'])\n",
    "    skipped_no_night = 0\n",
    "\n",
    "    for caid in tqdm(valid_caid, desc=\"Estimating home locations\"):\n",
    "        user_df = data.loc[data['caid'] == caid]\n",
    "        dt = user_df['datetime_pdt'].dt\n",
    "        is_night = (dt.hour >= night_start) | (dt.hour < night_end)\n",
    "        night_df = user_df[is_night]\n",
    "\n",
    "        if night_df.empty:\n",
    "            skipped_no_night += 1\n",
    "            continue\n",
    "\n",
    "        t = night_df['datetime_pdt'].astype(int) // 1e9\n",
    "        slots = (t // slot_size).astype(int)\n",
    "        night_df = night_df.assign(slot=slots)\n",
    "\n",
    "        superpings = (\n",
    "            night_df.groupby('slot')\n",
    "            .agg({'latitude': 'mean', 'longitude': 'mean'})\n",
    "            .dropna()\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        if len(superpings) == 0:\n",
    "            continue\n",
    "\n",
    "        model = MeanShift(\n",
    "            bandwidth=bandwidth_deg,\n",
    "            bin_seeding=True,\n",
    "            min_bin_freq=2,\n",
    "            max_iter=50\n",
    "        )\n",
    "        model.fit(superpings)\n",
    "        home_lat, home_lon = model.cluster_center\n",
    "\n",
    "        homes.append({\n",
    "            'caid': caid,\n",
    "            'latitude': home_lat,\n",
    "            'longitude': home_lon\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files for Binned HDA:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Estimating home locations:   4%|▎         | 542/15444 [02:44<1:13:01,  3.40it/s]"
     ]
    }
   ],
   "source": [
    "def run_binned_hda_on_all_2019_data():\n",
    "    input_folder = \"00_Data/02_Cleaned_Sample_Data/2019_Cleaned_Data\"\n",
    "    output_folder = \"00_Data/04_HDA_Sample_Data/Binned_HDA\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    parquet_files = [\n",
    "        f for f in os.listdir(input_folder)\n",
    "        if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    for file in tqdm(parquet_files, desc=\"Processing files for Binned HDA\"):\n",
    "        input_path = os.path.join(input_folder, file)\n",
    "        output_path = os.path.join(output_folder, f\"binned_hda_{file.replace('.parquet', '.csv')}\")\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"Already processed {file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = pd.read_parquet(input_path, engine=\"pyarrow\")\n",
    "            homes_df_binned = run_binned_hda_for_single_file(data)\n",
    "            homes_df_binned.to_csv(output_path, index=False)\n",
    "            print(f\"{file}: {len(homes_df_binned):,} users processed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "run_binned_hda_on_all_2019_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_binned_hda_results(folder_path: str) -> pd.DataFrame:\n",
    "    csv_files = [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if f.startswith(\"binned_hda_\") and f.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {file}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        raise ValueError(\"No valid binned HDA files found.\")\n",
    "\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "binned_hda_folder = \"00_Data/04_HDA_Sample_Data/Binned_HDA\"\n",
    "all_binned_hda = load_all_binned_hda_results(binned_hda_folder)\n",
    "print(f\"Loaded {len(all_binned_hda):,} total users from binned HDA files.\")\n",
    "\n",
    "output_file = \"00_Data/04_HDA_Sample_Data/2019_all_users_binned_home_locations.csv\"\n",
    "all_binned_hda.to_csv(output_file, index=False)\n",
    "print(f\"Saved combined HDA results to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
